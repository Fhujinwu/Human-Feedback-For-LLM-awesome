# Human-Feedback-For-LLM-awesome
We would like to maintain an up-to-date list of progress (papers, blogs, codes, and *etc.*) made in **Human Feedback For AI** (LLM,Text-image and other task), and provide a guide for some of the papers that have received wide interest.
Please feel free to [open an issue](Fhujinwu/Human-Feedback-For-LLM-awesome) to add papers.

## <a name="toc">Table of Contents</a>

- <a href="#human-feedback-LLM">Human Feedback for LLM</a>
- <a href="#human-feedback-Text-image">Human Feedback for Text-Image</a>

## <a name="human-feedback-LLM">Human Feedback for LLM</a>

## <a name="human-feedback-Text-image">Human Feedback for Text-Image</a>
* Aligning text-to-image models using human feedback, arxiv'23. [[paper]](https://arxiv.org/pdf/2302.12192.pdf) [[code]](https://github.com/tgxs002/align_sd) [[blogs]](https://mp.weixin.qq.com/s/FrqpybryiJ-ikO4ZVeISIg)
* Better aligning text-to-image models with human preference, arxiv'23. [[paper]](https://arxiv.org/pdf/2303.14420.pdf)
* DPOK: Reinforcement Learning for Fine-tuning Text-to-Image Diffusion Models, arxiv'23. [[paper]](https://arxiv.org/pdf/2305.16381.pdf)
* ImageReward: Learning and Evaluating Human Preferences for Text-to-Image Generation, arxiv'23. [[paper]](https://arxiv.org/pdf/2304.05977.pdf) [[code]](https://github.com/THUDM/ImageReward)
